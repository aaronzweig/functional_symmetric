{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import Symmetric, DeepSets, KNN, KK\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_test = 32\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overkill(nn.Module):\n",
    "    def __init__(self, input_dim, h1, h2, h3, output_dim = 1):\n",
    "        super(Overkill, self).__init__()\n",
    "        \n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.h3 = h3\n",
    "        self.input_dim = input_dim + 1 #Explicit bias term to simplify path norm\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.rho = None\n",
    "        self.phi = None\n",
    "        self.reinit()\n",
    "    \n",
    "    def reinit(self):\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h1, self.h1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.rho = nn.Sequential(\n",
    "            nn.Linear(self.h1, self.h2),\n",
    "#             nn.BatchNorm1d(self.h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h2, self.h3),\n",
    "#             nn.BatchNorm1d(self.h3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h3, self.output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        batch_size, input_set_dim, input_dim = x.shape\n",
    "        \n",
    "        x = x.view(-1, input_dim)\n",
    "        z = self.phi(x)\n",
    "        z = z.view(batch_size, input_set_dim, -1)\n",
    "        z = torch.mean(z, 1)\n",
    "        return self.rho(z)\n",
    "    \n",
    "    def regularize(self, lamb):\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloud(object):\n",
    "\n",
    "    def __init__(self, cloud_size):\n",
    "        self.cloud_size = cloud_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        flat = image.flatten()\n",
    "        flat = (flat > 0.5).float() * flat\n",
    "        \n",
    "        vertex_count = torch.nonzero(flat).shape[0]\n",
    "        \n",
    "        size = min(self.cloud_size, vertex_count)\n",
    "        \n",
    "        args = torch.argsort(flat)[-size:].int()\n",
    "        args = args[torch.randperm(size)]\n",
    "        if size < self.cloud_size:\n",
    "            repeat = self.cloud_size // size + 1\n",
    "            args = args.repeat(repeat)[:self.cloud_size]\n",
    "        \n",
    "        \n",
    "        rows = (args / 28.).int()\n",
    "        cols = torch.fmod(args, 28)\n",
    "        \n",
    "        image = torch.zeros(self.cloud_size, 4)\n",
    "        \n",
    "        image[:,0] = (rows - 14) / 28.\n",
    "        image[:,1] = (cols - 14) / 28.\n",
    "        image[:,2] = flat[args.long()]\n",
    "        image[:,3] = 1 #bias term\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8840617710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###TEST\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.ToTensor()\n",
    "                             ),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (image, y) = next(examples)\n",
    "\n",
    "image = image[0][0]\n",
    "cloud_size = 200\n",
    "x = PointCloud(cloud_size)(image)\n",
    "rows = 28 * x[:,0] + 14\n",
    "cols = 28 * x[:,1] + 14\n",
    "\n",
    "new_im = torch.zeros_like(image)\n",
    "\n",
    "for i in range(cloud_size):\n",
    "    r = rows[i].int().item()\n",
    "    c = cols[i].int().item()\n",
    "    new_im[r,c] = x[i,2].item()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(image, cmap='gray', interpolation='none')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(new_im, cmap='gray', interpolation='none')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "cloud_size = 200\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                                 PointCloud(cloud_size)\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                                 PointCloud(cloud_size)\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 200, 4])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f88404f3908>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANtElEQVR4nO3db6hc9Z3H8c/H2IhEY5IN3o1R17bkwcrK6hplIWXjIi2uCLFil+aBprZsKlRpcR+sZB8ksBR0sV32iYVblKZLtVS0ayyFNsSy/gGD15A1sTFRk2iTXJNNIjRVoZvkuw/uyXKNd35zM+fMnLn3+37BZe6c75w5X4/3k3NmfnPm54gQgNnvvLYbADAYhB1IgrADSRB2IAnCDiRx/iA3Zpu3/oE+iwhPtbzWkd32LbZ3237b9oN1ngtAf7nXcXbbcyTtkfRFSQckvSppdUT8trAOR3agz/pxZL9R0tsRsTci/ijpp5JW1Xg+AH1UJ+xLJf1u0v0D1bJPsL3W9pjtsRrbAlBTnTfopjpV+NRpekSMShqVOI0H2lTnyH5A0hWT7l8u6VC9dgD0S52wvyppme3P2p4r6auSNjXTFoCm9XwaHxEnbd8n6VeS5kh6PCLeaKwzAI3qeeitp43xmh3ou758qAbAzEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEj1P2QxI0qOPPlqs33nnnR1rixcvrrXtbdu2FevLly+v9fyzTa2w294v6YSkU5JORgR7FxhSTRzZ/zYijjbwPAD6iNfsQBJ1wx6Sfm37Ndtrp3qA7bW2x2yP1dwWgBrqnsaviIhDti+VtNn2mxHxwuQHRMSopFFJsh01twegR7WO7BFxqLo9Iunnkm5soikAzes57Lbn2b74zO+SviRpZ1ONAWiWI3o7s7b9OU0czaWJlwNPRMR3u6zDafwMc/DgwWJ9yZIlxfo777zTsfbcc88V173nnnuK9fnz5xfrtjvWPv744+K6jzzySLG+fv36Yr1NETHlf3jPr9kjYq+kv+y5IwADxdAbkARhB5Ig7EAShB1IgrADSfQ89NbTxhh6G7jnn3++WF+5cmWt558zZ06t9UuOHTtWrC9YsKBYLw29dfu73717d7F+9dVXF+tt6jT0xpEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Lgq6RngTfffLNjbdmyZcV1X3nllWJ9xYoVPfU0Hd0uM507d26x/sQTTxTrd911V8fa4cOHi+tedNFFxfpMxJEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgevYZ4PTp08V66f9htymV77///p56asLx48eL9UsuuaRYr3Mt/alTp4r17du3F+vXX399z9vuN65nB5Ij7EAShB1IgrADSRB2IAnCDiRB2IEkuJ59ALqNdd97773F+ocfflisX3zxxefc0zBYtGhRa9sufae8JL388ssD6mRwuh7ZbT9u+4jtnZOWLbK92fZb1e3C/rYJoK7pnMb/SNItZy17UNKWiFgmaUt1H8AQ6xr2iHhB0tmfa1wlaWP1+0ZJtzfcF4CG9fqafSQixiUpIsZtX9rpgbbXSlrb43YANKTvb9BFxKikUYkLYYA29Tr0dtj2Ekmqbo801xKAfug17Jskral+XyPp2WbaAdAvXa9nt/2kpJskLZZ0WNJ6Sf8p6WeSrpT0nqSvRET54mTlPY3vdu30Rx99VKzP1HH0tpW+B2B8fLy47tKlS5tuZ2A6Xc/e9TV7RKzuULq5VkcABoqPywJJEHYgCcIOJEHYgSQIO5AEl7g2YMOGDbXWf++995ppJJluw2elIc+ZPLTWK47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEUzYPwLvvvlusX3755cV6t6893rt3b8fapk2biuvW9cADD/TtuQ8dOlSsj4yMFOt1pnSeyZiyGUiOsANJEHYgCcIOJEHYgSQIO5AEYQeSYJx9BhgbGyvWr7vuugF18mndPgMwyL+vszHO/kkc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZkztx4kSxPm/evGK92zh76flPnjxZXPfCCy8s1i+44IJi/aGHHupYW7duXXHdmazncXbbj9s+YnvnpGUbbB+0vb36ubXJZgE0bzqn8T+SdMsUy/8tIq6tfn7ZbFsAmtY17BHxgqTjA+gFQB/VeYPuPtuvV6f5Czs9yPZa22O2yx/wBtBXvYb9B5I+L+laSeOSvtfpgRExGhHLI2J5j9sC0ICewh4RhyPiVESclvRDSTc22xaApvUUdttLJt39sqSdnR4LYDh0HWe3/aSkmyQtlnRY0vrq/rWSQtJ+Sd+MiPJk2WKcvV+OHTvWsbZgwYJaz91t7vgXX3yxWL/77rt73vazzz5brN92223FOtezf9L501hx9RSLH6vdEYCB4uOyQBKEHUiCsANJEHYgCcIOJNH13XjU99RTTxXrq1atKtbPP7/8v6k0fNpt+OqOO+4o1tt0zTXXtN3CrMKRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9Afv27SvWr7zyymL96NGjxfrIyMg59zQbLF26tFjfsWPHgDqZHTiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASTNncgFOnThXrL730UrG+cuXKJtuZMbZu3VqsL19enkQo61dFd9PzlM0AZgfCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYGnD59ulg/7zz+TZ1Kt/32/vvvF+uXXXZZk+3MGj2Ps9u+wvZvbO+y/Ybtb1fLF9nebPut6nZh000DaM50DjknJf1jRPy5pL+W9C3bV0t6UNKWiFgmaUt1H8CQ6hr2iBiPiG3V7yck7ZK0VNIqSRurh22UdHu/mgRQ3zl9B53tqyRdJ2mrpJGIGJcm/kGwfWmHddZKWluvTQB1TTvsti+S9LSk70TE7+0p3wP4lIgYlTRaPcesfIMOmAmm9Tax7c9oIug/iYhnqsWHbS+p6kskHelPiwCa0PXI7olD+GOSdkXE9yeVNklaI+mh6rY8N/As1m34csuWLcX6zTff3GQ7Q+XYsWMda932G0NrzZrOafwKSXdJ2mF7e7VsnSZC/jPb35D0nqSv9KdFAE3oGvaIeElSpxfos/eQBMwyfLQLSIKwA0kQdiAJwg4kQdiBJJiyuQF79uwp1rt9JfJM9sEHHxTr8+fP71h7+OGHm24HBRzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJvkp6ALpN6Xz06NFifWRkpMl2PmHz5s3F+k033VSsd/v7mTt37rm2hJqYshlIjrADSRB2IAnCDiRB2IEkCDuQBGEHkuB69gGYM2dOsb5v375ivdvUxv38rMS2bduK9RtuuKFv20azOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJdr2e3fYWkH0v6U0mnJY1GxL/b3iDpHyT9T/XQdRHxyy7PlfJ6dmCQOl3PPp2wL5G0JCK22b5Y0muSbpf095L+EBGPTLcJwg70X6ewT2d+9nFJ49XvJ2zvkrS02fYA9Ns5vWa3fZWk6yRtrRbdZ/t124/bXthhnbW2x2yP1eoUQC3T/g462xdJ+i9J342IZ2yPSDoqKST9iyZO9b/e5Tk4jQf6rOfX7JJk+zOSfiHpVxHx/SnqV0n6RUT8RZfnIexAn/X8hZO2LekxSbsmB7164+6ML0vaWbdJAP0znXfjvyDpRUk7NDH0JknrJK2WdK0mTuP3S/pm9WZe6bk4sgN9Vus0vimEHeg/vjceSI6wA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQxKCnbD4q6d1J9xdXy4bRsPY2rH1J9NarJnv7s06FgV7P/qmN22MRsby1BgqGtbdh7Uuit14NqjdO44EkCDuQRNthH215+yXD2tuw9iXRW68G0lurr9kBDE7bR3YAA0LYgSRaCbvtW2zvtv227Qfb6KET2/tt77C9ve356ao59I7Y3jlp2SLbm22/Vd1OOcdeS71tsH2w2nfbbd/aUm9X2P6N7V2237D97Wp5q/uu0NdA9tvAX7PbniNpj6QvSjog6VVJqyPitwNtpAPb+yUtj4jWP4Bh+28k/UHSj89MrWX7XyUdj4iHqn8oF0bEPw1Jbxt0jtN496m3TtOMf00t7rsmpz/vRRtH9hslvR0ReyPij5J+KmlVC30MvYh4QdLxsxavkrSx+n2jJv5YBq5Db0MhIsYjYlv1+wlJZ6YZb3XfFfoaiDbCvlTS7ybdP6Dhmu89JP3a9mu217bdzBRGzkyzVd1e2nI/Z+s6jfcgnTXN+NDsu16mP6+rjbBPNTXNMI3/rYiIv5L0d5K+VZ2uYnp+IOnzmpgDcFzS99pspppm/GlJ34mI37fZy2RT9DWQ/dZG2A9IumLS/cslHWqhjylFxKHq9oikn2viZccwOXxmBt3q9kjL/fy/iDgcEaci4rSkH6rFfVdNM/60pJ9ExDPV4tb33VR9DWq/tRH2VyUts/1Z23MlfVXSphb6+BTb86o3TmR7nqQvafimot4kaU31+xpJz7bYyycMyzTenaYZV8v7rvXpzyNi4D+SbtXEO/LvSPrnNnro0NfnJP139fNG271JelITp3X/q4kzom9I+hNJWyS9Vd0uGqLe/kMTU3u/rolgLWmpty9o4qXh65K2Vz+3tr3vCn0NZL/xcVkgCT5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/B8/J2+J9H8PaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(train_loader)\n",
    "batch_idx, (batch_x, batch_y) = next(examples)\n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "\n",
    "x = batch_x[0]\n",
    "\n",
    "image = torch.zeros((28, 28))\n",
    "for i in range(x.shape[0]):\n",
    "    r = (28 * x[i,0] + 14).int().item()\n",
    "    c = (28 * x[i,1] + 14).int().item()\n",
    "    image[r,c] = x[i,2]\n",
    "    \n",
    "plt.imshow(image, cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, iterations, lamb = 0.1, lr = 0.003):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        print(\"iter\", i)\n",
    "        iter_losses = []\n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss += model.regularize(lamb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            iter_losses.append(loss.item())\n",
    "        print(\"iter_loss: \", np.mean(np.array(iter_losses)))\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x)\n",
    "        preds = torch.argmax(outputs, dim = 1)\n",
    "        correct += preds.eq(y).sum()\n",
    "        total += y.shape[0]\n",
    "    \n",
    "    return 1 - (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, dataloader, iterations, lambs, verbose):\n",
    "    models = []\n",
    "    for lamb in lambs:\n",
    "        model_copy = copy.deepcopy(model)\n",
    "        losses = train(model_copy, dataloader, iterations, lamb)\n",
    "        models.append(model_copy)\n",
    "        if verbose:\n",
    "            print(losses[::100])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(hidden_dim, iterations, input_dim = 3, verbose = False):\n",
    "        \n",
    "    f1 = Symmetric(input_dim, hidden_dim, hidden_dim, 10)\n",
    "    f2 = KNN(input_dim, hidden_dim, hidden_dim, 10)\n",
    "    f3 = KK(input_dim, hidden_dim, hidden_dim, 10)\n",
    "\n",
    "    f1.__name__ = \"S1\"\n",
    "    f2.__name__ = \"S2\"\n",
    "    f3.__name__ = \"S3\"\n",
    "\n",
    "    models = [f1, f2, f3]\n",
    "    \n",
    "    lambs = [0., 1e-6, 1e-4, 1e-2]\n",
    "\n",
    "    for model in models:\n",
    "        print(\"model\", model.__name__)\n",
    "        cv_models = cross_validate(model, train_loader, iterations, lambs, verbose)\n",
    "        \n",
    "        validation_errors = np.zeros_like(lambs)\n",
    "        for i, cv_model in enumerate(cv_models):\n",
    "            validation_errors[i] = test(cv_model, train_loader)\n",
    "        \n",
    "        i = np.argmin(validation_errors)\n",
    "        lamb = lambs[i]\n",
    "            \n",
    "        runs = 3\n",
    "        run_errors = np.zeros(runs)\n",
    "        for i in range(runs):\n",
    "            print(\"run\", i)\n",
    "            model_copy = copy.deepcopy(model)\n",
    "            model_copy.reinit()\n",
    "            train(model_copy, train_loader, iterations, lamb)\n",
    "            run_errors[i] = test(model_copy, test_loader)\n",
    "        \n",
    "        mean_error = np.mean(run_errors)\n",
    "        std_error = np.std(run_errors)\n",
    "        \n",
    "        print(\"mean: {}, std: {}\".format(mean_error, std_error))\n",
    "        \n",
    "#         if log_plot:\n",
    "#             plt.semilogy(N_list, mean_error, label = model.__name__)\n",
    "#         else:\n",
    "#             plt.plot(N_list, mean_error, label = model.__name__)\n",
    "#         plt.fill_between(N_list, mean_error - std_error, mean_error + std_error, alpha = 0.2)\n",
    "\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.ylim([1e-5, 1e-1]) \n",
    "#     plt.xlabel(\"N\")\n",
    "#     plt.ylabel(\"Mean Square Error\")\n",
    "#     narrow_str = \"Narrow\" if narrow else \"Wide\"\n",
    "#     plt.title(narrow_str + \" generalization for \" + objective.__name__)\n",
    "#     scale_str = \"\" if not scaleup else \"scaled\"\n",
    "#     plt.savefig(\"plots_high_dim/\" + objective.__name__ + \"_\" + narrow_str + \"_\" + str(input_dim) + scale_str)\n",
    "# #     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_models(100, 3, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "iter_loss:  1.5613089074452717\n",
      "iter 1\n",
      "iter_loss:  0.7119634001255035\n",
      "iter 2\n",
      "iter_loss:  0.5444821759541829\n",
      "iter 3\n",
      "iter_loss:  0.465437133872509\n",
      "iter 4\n",
      "iter_loss:  0.41835560990174614\n",
      "iter 5\n",
      "iter_loss:  0.379733114528656\n",
      "iter 6\n",
      "iter_loss:  0.3580512909293175\n",
      "iter 7\n",
      "iter_loss:  0.3399294368346532\n",
      "iter 8\n",
      "iter_loss:  0.3273130679567655\n",
      "iter 9\n",
      "iter_loss:  0.32020504401524863\n",
      "iter 10\n",
      "iter_loss:  0.3082508816818396\n",
      "iter 11\n",
      "iter_loss:  0.3028236623942852\n",
      "iter 12\n",
      "iter_loss:  0.29622552425265314\n",
      "iter 13\n",
      "iter_loss:  0.28976431861519814\n",
      "iter 14\n",
      "iter_loss:  0.2831877281924089\n",
      "iter 15\n",
      "iter_loss:  0.27986823006073636\n",
      "iter 16\n",
      "iter_loss:  0.27284333741466205\n",
      "iter 17\n",
      "iter_loss:  0.2711389164249102\n",
      "iter 18\n",
      "iter_loss:  0.26601546550790467\n",
      "iter 19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-738a4e503a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# model = Symmetric(input_dim, h1, h2, 10).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f63d3ced2858>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, iterations, lamb, lr)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0miter_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/BrunaGroup/aaron/envs/prime/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/BrunaGroup/aaron/envs/prime/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/BrunaGroup/aaron/envs/prime/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/BrunaGroup/aaron/envs/prime/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/BrunaGroup/aaron/envs/prime/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/BrunaGroup/aaron/envs/prime/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-84a094f58e90>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvertex_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/BrunaGroup/aaron/envs/prime/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = 3\n",
    "h1 = 100\n",
    "h2 = 500\n",
    "h3 = 500\n",
    "\n",
    "model = Overkill(input_dim, h1, h2, h3, 10).to(device)\n",
    "# model = Symmetric(input_dim, h1, h2, 10).to(device)\n",
    "\n",
    "train(model, train_loader, 50, lamb = 0.0, lr = 0.003)\n",
    "\n",
    "error = test(model, train_loader)\n",
    "print(\"train error: \", error)\n",
    "\n",
    "error = test(model, test_loader)\n",
    "print(\"test error: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aaron-prime]",
   "language": "python",
   "name": "conda-env-aaron-prime-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
