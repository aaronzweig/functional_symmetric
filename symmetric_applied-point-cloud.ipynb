{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import Symmetric, DeepSets, KNN, KK\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_test = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overkill(nn.Module):\n",
    "    def __init__(self, input_dim, h1, h2, h3, output_dim = 1):\n",
    "        super(Overkill, self).__init__()\n",
    "        \n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.h3 = h3\n",
    "        self.input_dim = input_dim + 1 #Explicit bias term to simplify path norm\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.rho = None\n",
    "        self.phi = None\n",
    "        self.reinit()\n",
    "    \n",
    "    def reinit(self):\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h1, self.h1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.rho = nn.Sequential(\n",
    "            nn.Linear(self.h1, self.h2),\n",
    "#             nn.BatchNorm1d(self.h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h2, self.h3),\n",
    "#             nn.BatchNorm1d(self.h3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h3, self.output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        batch_size, input_set_dim, input_dim = x.shape\n",
    "        \n",
    "        x = x.view(-1, input_dim)\n",
    "        z = self.phi(x)\n",
    "        z = z.view(batch_size, input_set_dim, -1)\n",
    "        z = torch.mean(z, 1)\n",
    "        return self.rho(z)\n",
    "    \n",
    "    def regularize(self, lamb):\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloud(object):\n",
    "\n",
    "    def __init__(self, cloud_size):\n",
    "        self.cloud_size = cloud_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        flat = image.flatten()\n",
    "        flat = (flat > 0.5).float() * flat\n",
    "        \n",
    "        vertex_count = torch.nonzero(flat).shape[0]\n",
    "        \n",
    "        size = min(self.cloud_size, vertex_count)\n",
    "        \n",
    "        args = torch.argsort(flat)[-size:].int()\n",
    "        args = args[torch.randperm(size)]\n",
    "        if size < self.cloud_size:\n",
    "            repeat = self.cloud_size // size + 1\n",
    "            args = args.repeat(repeat)[:self.cloud_size]\n",
    "        \n",
    "        \n",
    "        rows = torch.floor_divide(args, 28)\n",
    "        cols = torch.fmod(args, 28)\n",
    "        \n",
    "        image = torch.zeros(self.cloud_size, 4)\n",
    "        \n",
    "        image[:,0] = (rows - 14) / 28.\n",
    "        image[:,1] = (cols - 14) / 28.\n",
    "        image[:,2] = flat[args.long()]\n",
    "        image[:,3] = 1 #bias term\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1271d41d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###TEST\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.ToTensor()\n",
    "                             ),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (image, y) = next(examples)\n",
    "\n",
    "image = image[0][0]\n",
    "cloud_size = 200\n",
    "x = PointCloud(cloud_size)(image)\n",
    "rows = 28 * x[:,0] + 14\n",
    "cols = 28 * x[:,1] + 14\n",
    "\n",
    "new_im = torch.zeros_like(image)\n",
    "\n",
    "for i in range(cloud_size):\n",
    "    r = rows[i].int().item()\n",
    "    c = cols[i].int().item()\n",
    "    new_im[r,c] = x[i,2].item()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(image, cmap='gray', interpolation='none')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(new_im, cmap='gray', interpolation='none')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_size = 200\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                                 PointCloud(cloud_size)\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                                 PointCloud(cloud_size)\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 200, 4])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127181790>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(train_loader)\n",
    "batch_idx, (batch_x, batch_y) = next(examples)\n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "\n",
    "x = batch_x[0]\n",
    "\n",
    "image = torch.zeros((28, 28))\n",
    "for i in range(x.shape[0]):\n",
    "    r = (28 * x[i,0] + 14).int().item()\n",
    "    c = (28 * x[i,1] + 14).int().item()\n",
    "    image[r,c] = x[i,2]\n",
    "    \n",
    "plt.imshow(image, cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, iterations, lamb = 0.1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        print(\"iter\", i)\n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss += model.regularize(lamb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(dataloader):\n",
    "        outputs = model(x)\n",
    "        preds = torch.argmax(outputs, dim = 1)\n",
    "        correct += preds.eq(y).sum()\n",
    "        total += y.shape[0]\n",
    "    \n",
    "    return 1 - (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, dataloader, iterations, lambs, verbose):\n",
    "    models = []\n",
    "    for lamb in lambs:\n",
    "        model_copy = copy.deepcopy(model)\n",
    "        losses = train(model_copy, dataloader, iterations, lamb)\n",
    "        models.append(model_copy)\n",
    "        if verbose:\n",
    "            print(losses[::100])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(hidden_dim, iterations, input_dim = 3, verbose = False):\n",
    "        \n",
    "    f1 = Symmetric(input_dim, hidden_dim, hidden_dim, 10)\n",
    "    f2 = KNN(input_dim, hidden_dim, hidden_dim, 10)\n",
    "    f3 = KK(input_dim, hidden_dim, hidden_dim, 10)\n",
    "\n",
    "    f1.__name__ = \"S1\"\n",
    "    f2.__name__ = \"S2\"\n",
    "    f3.__name__ = \"S3\"\n",
    "\n",
    "    models = [f1, f2, f3]\n",
    "    \n",
    "    lambs = [0., 1e-6, 1e-4, 1e-2]\n",
    "\n",
    "    for model in models:\n",
    "        print(\"model\", model.__name__)\n",
    "        cv_models = cross_validate(model, train_loader, iterations, lambs, verbose)\n",
    "        \n",
    "        validation_errors = np.zeros_like(lambs)\n",
    "        for i, cv_model in enumerate(cv_models):\n",
    "            validation_errors[i] = test(cv_model, train_loader)\n",
    "        \n",
    "        i = np.argmin(validation_errors)\n",
    "        lamb = lambs[i]\n",
    "            \n",
    "        runs = 3\n",
    "        run_errors = np.zeros(runs)\n",
    "        for i in range(runs):\n",
    "            print(\"run\", i)\n",
    "            model_copy = copy.deepcopy(model)\n",
    "            model_copy.reinit()\n",
    "            train(model_copy, train_loader, iterations, lamb)\n",
    "            run_errors[i] = test(model_copy, test_loader)\n",
    "        \n",
    "        mean_error = np.mean(run_errors)\n",
    "        std_error = np.std(run_errors)\n",
    "        \n",
    "        print(\"mean: {}, std: {}\".format(mean_error, std_error))\n",
    "        \n",
    "#         if log_plot:\n",
    "#             plt.semilogy(N_list, mean_error, label = model.__name__)\n",
    "#         else:\n",
    "#             plt.plot(N_list, mean_error, label = model.__name__)\n",
    "#         plt.fill_between(N_list, mean_error - std_error, mean_error + std_error, alpha = 0.2)\n",
    "\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.ylim([1e-5, 1e-1]) \n",
    "#     plt.xlabel(\"N\")\n",
    "#     plt.ylabel(\"Mean Square Error\")\n",
    "#     narrow_str = \"Narrow\" if narrow else \"Wide\"\n",
    "#     plt.title(narrow_str + \" generalization for \" + objective.__name__)\n",
    "#     scale_str = \"\" if not scaleup else \"scaled\"\n",
    "#     plt.savefig(\"plots_high_dim/\" + objective.__name__ + \"_\" + narrow_str + \"_\" + str(input_dim) + scale_str)\n",
    "# #     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_models(100, 3, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "[2.304962635040283, 2.304004669189453, 2.313499927520752, 2.292806386947632, 2.2766780853271484, 1.8061996698379517, 1.4619487524032593, 1.4171719551086426, 1.2893046140670776, 1.2537320852279663, 0.9859843254089355, 0.9115166664123535, 0.8048770427703857, 1.3117586374282837, 0.8312364220619202, 0.8835158348083496, 1.0444718599319458, 1.0439244508743286, 1.0353549718856812, 0.8742231726646423, 0.755380392074585, 0.9939143061637878, 0.6384285688400269, 0.9634263515472412, 0.8039736151695251, 0.8794617652893066, 0.6583983302116394, 0.6040084958076477, 0.5601102709770203, 0.819321870803833, 0.7466979026794434, 0.6750922799110413, 0.8048166632652283, 0.5295870304107666, 0.6268677711486816, 0.8673180341720581, 0.7615747451782227, 0.3698125183582306, 0.5039823055267334, 0.5085453391075134, 0.3401818573474884, 0.5270726680755615, 0.523725688457489, 0.520521342754364, 0.8026604652404785, 0.7600938081741333, 0.6821429133415222, 0.8237740993499756, 0.6904517412185669, 0.39839622378349304, 0.38870126008987427, 1.0235416889190674, 0.5755260586738586, 0.36875420808792114, 0.4833773970603943, 0.6736610531806946, 0.2843593657016754, 0.6636174917221069, 0.3595641851425171, 0.535494863986969, 0.7557466626167297, 0.6211010813713074, 0.5435792803764343, 0.6211990118026733, 0.30764102935791016, 0.3322342336177826, 0.3402758836746216, 0.5483832955360413, 0.7000201940536499, 0.32098257541656494, 0.501580536365509, 0.3413544297218323, 0.48000314831733704, 0.2910561263561249, 0.23101283609867096, 0.550441563129425, 0.3374386131763458, 0.7035595178604126, 0.468142569065094, 0.4703243672847748, 0.32267266511917114, 0.24269093573093414, 0.49170494079589844, 0.5121666193008423, 0.2814837098121643, 0.27271267771720886, 0.6844574809074402, 0.45842230319976807, 0.2897897958755493, 0.48010993003845215, 0.41556641459465027, 0.48991724848747253, 0.38804566860198975, 0.5312122702598572, 0.37931591272354126, 0.33393394947052, 0.45584091544151306, 0.23043659329414368, 0.24499662220478058, 0.34400761127471924, 0.47265058755874634, 0.24933473765850067, 0.29076093435287476, 0.33620133996009827, 0.6280333399772644, 0.8004967570304871, 0.3402060866355896, 0.2797466814517975, 0.26432716846466064, 0.37767547369003296, 0.5756452083587646, 0.18466652929782867, 0.5170092582702637, 0.27695247530937195, 0.2529263496398926, 0.39263060688972473, 0.2651291489601135, 0.5252676606178284, 0.34028831124305725, 0.16791509091854095, 0.2773357331752777, 0.21219192445278168, 0.30764296650886536, 0.2524105906486511, 0.44581595063209534, 0.5981315970420837, 0.06239304691553116, 0.3289799988269806, 0.36590591073036194, 0.39643943309783936, 0.24924126267433167, 0.27753746509552, 0.523101270198822, 0.226521298289299, 0.3665342330932617, 0.5158181190490723, 0.3175891637802124, 0.6995155811309814, 0.2874746322631836, 0.2800404727458954, 0.23658055067062378, 0.11092258989810944, 0.3341575860977173, 0.1788606196641922, 0.30536094307899475, 0.5537453889846802, 0.3058934807777405, 0.2353789061307907, 0.2588036060333252, 0.35935959219932556, 0.25082606077194214, 0.5663309693336487, 0.32542017102241516, 0.19490979611873627, 0.285890132188797, 0.29403018951416016, 0.25940293073654175, 0.4569903612136841, 0.4347027540206909, 0.26895710825920105, 0.3525505065917969, 0.2311255782842636, 0.3473016321659088, 0.24279598891735077, 0.14189985394477844, 0.3146839737892151, 0.17406462132930756, 0.28993380069732666, 0.21292860805988312, 0.09008459746837616, 0.22544023394584656, 0.7106945514678955, 0.17037129402160645, 0.2595767676830292, 0.21036747097969055, 0.34296104311943054, 0.2906632125377655, 0.46193554997444153, 0.23784644901752472, 0.3017273545265198, 0.36310896277427673, 0.32816246151924133, 0.20746658742427826, 0.4878399968147278, 0.12113406509160995, 0.47324487566947937, 0.2958938479423523, 0.5461719632148743]\n",
      "tensor(0.1184)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 3\n",
    "h1 = 100\n",
    "h2 = 800\n",
    "h3 = 800\n",
    "\n",
    "model = Overkill(input_dim, h1, h2, h3, 10)\n",
    "losses = train(model, train_loader, 10, lamb = 0.0)\n",
    "print(losses[::100])\n",
    "\n",
    "error = test(model, test_loader)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prime] *",
   "language": "python",
   "name": "conda-env-prime-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
